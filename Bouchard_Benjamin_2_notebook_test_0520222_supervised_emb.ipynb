{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Modules import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# import math\n",
    "# import re\n",
    "# from collections import defaultdict\n",
    "# from html.parser import HTMLParser\n",
    "# from itertools import accumulate,chain,takewhile\n",
    "# import itertools\n",
    "# import warnings\n",
    "# import itertools\n",
    "# from pathlib import Path,PureWindowsPath,PurePosixPath\n",
    "\n",
    "# #wordcloud\n",
    "# import wordcloud\n",
    "\n",
    "# # \n",
    "# from scipy.sparse import csr_matrix\n",
    "\n",
    "# #pygments\n",
    "# from pygments.lexers import guess_lexer\n",
    "# from pygments.util  import ClassNotFound\n",
    "\n",
    "# # sklearn\n",
    "# from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "# from sklearn.preprocessing import MultiLabelBinarizer,StandardScaler\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.multiclass import OneVsRestClassifier\n",
    "# from sklearn.linear_model import SGDClassifier\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.metrics import jaccard_score,confusion_matrix\n",
    "\n",
    "\n",
    "# #gensim\n",
    "# from gensim.models.ldamodel import LdaModel\n",
    "# from gensim.corpora import Dictionary\n",
    "\n",
    "# #vis\n",
    "# import pyLDAvis\n",
    "# import pyLDAvis.gensim_models as gensimvis\n",
    "\n",
    "# #nltk\n",
    "# import nltk\n",
    "\n",
    "# #spacy\n",
    "# import spacy\n",
    "\n",
    "# #bitarray\n",
    "# # from  bitarray import bitarray\n",
    "# # from  bitarray.util import ba2int\n",
    "\n",
    "# #joblib\n",
    "# import joblib\n",
    "\n",
    "# #local\n",
    "# from Bouchard_Benjamin_1_notebook_exploration_0520222 import *\n",
    "# import vectorizer as vectz\n",
    "# import lda as ldam\n",
    "\n",
    "# # from importlib import reload\n",
    "# # reload(vectz)\n",
    "# warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from src  import classify\n",
    "from src import io_file\n",
    "from src import tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Id</th>\n",
       "      <th>Score</th>\n",
       "      <th>ViewCount</th>\n",
       "      <th>FavoriteCount</th>\n",
       "      <th>AnswerCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SQL Server 2008 Full Text Search (FTS) versus ...</td>\n",
       "      <td>&lt;p&gt;I know there have been questions in the pas...</td>\n",
       "      <td>&lt;sql-server&gt;&lt;sql-server-2008&gt;&lt;full-text-search...</td>\n",
       "      <td>499247</td>\n",
       "      <td>40</td>\n",
       "      <td>18582</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XML Serialization and Inherited Types</td>\n",
       "      <td>&lt;p&gt;Following on from my &lt;a href=\"https://stack...</td>\n",
       "      <td>&lt;c#&gt;&lt;xml&gt;&lt;inheritance&gt;&lt;serialization&gt;&lt;xml-seri...</td>\n",
       "      <td>20084</td>\n",
       "      <td>86</td>\n",
       "      <td>56816</td>\n",
       "      <td>42</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MyISAM versus InnoDB</td>\n",
       "      <td>&lt;p&gt;I'm working on a projects which involves a ...</td>\n",
       "      <td>&lt;mysql&gt;&lt;database&gt;&lt;performance&gt;&lt;innodb&gt;&lt;myisam&gt;</td>\n",
       "      <td>20148</td>\n",
       "      <td>887</td>\n",
       "      <td>301985</td>\n",
       "      <td>390</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Recommended SQL database design for tags or ta...</td>\n",
       "      <td>&lt;p&gt;I've heard of a few ways to implement taggi...</td>\n",
       "      <td>&lt;sql&gt;&lt;database-design&gt;&lt;tags&gt;&lt;data-modeling&gt;&lt;ta...</td>\n",
       "      <td>20856</td>\n",
       "      <td>325</td>\n",
       "      <td>118552</td>\n",
       "      <td>307</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Specifying a mySQL ENUM in a Django model</td>\n",
       "      <td>&lt;p&gt;How do I go about specifying and using an E...</td>\n",
       "      <td>&lt;python&gt;&lt;mysql&gt;&lt;django&gt;&lt;django-models&gt;&lt;enums&gt;</td>\n",
       "      <td>21454</td>\n",
       "      <td>99</td>\n",
       "      <td>61572</td>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  SQL Server 2008 Full Text Search (FTS) versus ...   \n",
       "1              XML Serialization and Inherited Types   \n",
       "2                               MyISAM versus InnoDB   \n",
       "3  Recommended SQL database design for tags or ta...   \n",
       "4          Specifying a mySQL ENUM in a Django model   \n",
       "\n",
       "                                                Body  \\\n",
       "0  <p>I know there have been questions in the pas...   \n",
       "1  <p>Following on from my <a href=\"https://stack...   \n",
       "2  <p>I'm working on a projects which involves a ...   \n",
       "3  <p>I've heard of a few ways to implement taggi...   \n",
       "4  <p>How do I go about specifying and using an E...   \n",
       "\n",
       "                                                Tags      Id  Score  \\\n",
       "0  <sql-server><sql-server-2008><full-text-search...  499247     40   \n",
       "1  <c#><xml><inheritance><serialization><xml-seri...   20084     86   \n",
       "2     <mysql><database><performance><innodb><myisam>   20148    887   \n",
       "3  <sql><database-design><tags><data-modeling><ta...   20856    325   \n",
       "4      <python><mysql><django><django-models><enums>   21454     99   \n",
       "\n",
       "   ViewCount  FavoriteCount  AnswerCount  \n",
       "0      18582             26            5  \n",
       "1      56816             42            7  \n",
       "2     301985            390           25  \n",
       "3     118552            307            6  \n",
       "4      61572             21            9  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = io_file.load_input()\n",
    "one_doc = 1/len(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### supervised_classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ## Run config\n",
    "# def do_supervised_classify(data,config):\n",
    "#   pipe = config['pipe']\n",
    "#   ret = {}\n",
    "#   i = 0\n",
    "#   for (pipe_params_,params) in list(\n",
    "#                                   itertools.product(\n",
    "#                                                     pipe_params(pipe).make(config['pipe_params']),\n",
    "#                                                     pipe_params.gen_grid_params(config['params'])\n",
    "#                                                   )\n",
    "#                                   ):\n",
    "#     name = config_name(pipe_params_,params)\n",
    "#     print(f\"Run config:\\n{name} ...\")\n",
    "#     ret[i] = { \n",
    "#                   **supervised_classify(data,**params,pipe=pipe,pipe_params=pipe_params_), \n",
    "#                   **{'pipe_params':pipe_params_,'params':params,'name':name}\n",
    "#                 }\n",
    "#     i = i + 1\n",
    "#   return ret\n",
    "\n",
    "\n",
    "# def run_config(data,config,num):\n",
    "#     results = do_supervised_classify(data,config)\n",
    "#     save_result(results,f'supvs_res{num}')\n",
    "#     save_model(results,['model','vectorizer','name'],f'supvs_res{num}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### display results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def print_supervised_results(results):\n",
    "#     print(\">> ===== results ===== <<\")\n",
    "#     for k in range(len(results)):\n",
    "#         #k = list(results.keys())[i]\n",
    "#         name = results[k]['name']\n",
    "#         print(f\">> {k} <<{name}:\")\n",
    "#         print(' | '.join(map(lambda r: f\"{r}: {results[k][r]}\",['jaccard'])) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embedding Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### load pre-train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gensim.downloader as dwl\n",
    "# dwl.info()['models'].keys() \n",
    "# dwl.info()['models']['glove-wiki-gigaword-300']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = dwl.load('glove-wiki-gigaword-300')\n",
    "# w2v = vectz.W2V_Vectoriser(model,300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Wor2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'pipe':Pipeline( \n",
    "                steps=[\n",
    "                    ('classifier' , SGDClassifier(fit_intercept=False,n_jobs=-1,random_state=42))\n",
    "                ]\n",
    "            ),\n",
    "    'pipe_params':{'classifier__loss':['squared_error','hinge'],'classifier__max_iter':[5000]},\n",
    "    'params':{\n",
    "        'input_tokens':[''], \n",
    "        'Y_tokens':['ntags'],\n",
    "        'nb_tags':[50,100],\n",
    "        'embedding':[\"w2v\",\"bert\",\"use\"]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools.run_config(data,config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### config5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config5 = {\n",
    "#     'pipe':Pipeline( \n",
    "#                 steps=[\n",
    "#                     ('classifier' , SGDClassifier(fit_intercept=False,n_jobs=-1,random_state=42))\n",
    "#                 ]\n",
    "#             ),\n",
    "#     'pipe_params':{'classifier__loss':['squared_error','hinge'],'classifier__max_iter':[5000]},\n",
    "#     'params':{\n",
    "#         'body_tokens':['body-tokens'],\n",
    "#         'title_tokens':['title-tokens'], \n",
    "#         'Y_tokens':['ntags'],\n",
    "#         'nb_tags':[50,100], \n",
    "#         'body_min_df':[482*one_doc], \n",
    "#         'title_min_df':[58*one_doc], \n",
    "#         'body_max_df':[1492*one_doc], \n",
    "#         'title_max_df':[1.0],\n",
    "#         'vect':[w2v]\n",
    "#     }\n",
    "# }\n",
    "\n",
    "# tools.run_config(data,config5,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BERT & USE Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Content for BERT and USE embedding vectorisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['contents'] = data['Body'].apply(do_parse,args=(MyHTMLParser(filter= lambda x: True if x == 'code' else False ,container=Strcontainer() ),))\n",
    "# data['contents'] = pipe(data,\n",
    "# [\n",
    "# make_remove_signs_str(signs=[\"\\n\"]),\n",
    "# make_remove_signs_str(signs=['\"\\\"'])\n",
    "# ],\n",
    "# 'contents')\n",
    "# # Merge content and title\n",
    "# data['input-content'] = data.apply(lambda r: (r['Title'] + '. ' ) + r['contents'] ,axis=1)\n",
    "# data['input-content'] =  pipe(data,[lower_str],'input-content')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### BERT et USE vectorisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def do_vect(data,input_tokens):\n",
    "#     stratified_col_ = 'filtered-tag-str'\n",
    "#     nb_tags = 100\n",
    "#     Y_tokens = 'ntags'\n",
    "#     data[filtered_name(Y_tokens)] = filter_tokens(data,Y_tokens,nb_tags)\n",
    "#     data[stratified_col_] = data[filtered_name(Y_tokens)].apply(list_2_str)\n",
    "#     col_id='Id'\n",
    "    \n",
    "#     X_train, X_test, y_train, y_test = split_df(data,\n",
    "#                                                 x_cols=[input_tokens,col_id],\n",
    "#                                                 y_col=[Y_tokens,filtered_name(Y_tokens),col_id],\n",
    "#                                                 stratified_col = stratified_col_\n",
    "#                                                 )\n",
    "\n",
    "#     features = {}\n",
    "#     for mode in ['HF','TFhub','USE']:\n",
    "        \n",
    "#         if mode != 'USE':\n",
    "#             vect_obj = vectz.BERT_Vectoriser(mode=mode)\n",
    "#         else:\n",
    "#             vect_obj = vectz.USE_Vectorizer()\n",
    "\n",
    "#         #vectorize\n",
    "#         tmp = vect_obj.fit_transform(data[input_tokens])    \n",
    "#         features[mode] = { \n",
    "#             'X_':tmp[X_train.index],\n",
    "#             'Z_':tmp[X_test.index],\n",
    "#             'y_train_v_':y_train[filtered_name(Y_tokens)].values,\n",
    "#             'y_test_v_':y_test[filtered_name(Y_tokens)].values,\n",
    "#             'all_tokens_': data[filtered_name(Y_tokens)].values\n",
    "#         }\n",
    "\n",
    "#     #save\n",
    "#     joblib.dump(\n",
    "#     value=features,\n",
    "#     filename=f\"./tmp/berts_use_params.joblib\")\n",
    "\n",
    "#     return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#berts_use_params = do_vect(data,'input-content')\n",
    "# berts_use_params =  joblib.load(filename=f\"./tmp/berts_use_params.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### config7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_ = berts_use_params['HF']['X_']\n",
    "# Z_ = berts_use_params['HF']['Z_']\n",
    "# y_train_v_ = berts_use_params['HF']['y_train_v_']\n",
    "# y_test_v_  =  berts_use_params['HF']['y_test_v_']\n",
    "# all_tokens_ =  berts_use_params['HF']['all_tokens_']\n",
    "\n",
    "# config7 = {\n",
    "#     'pipe':Pipeline( \n",
    "#                 steps=[\n",
    "#                     ('classifier' , SGDClassifier(n_jobs=-1,random_state=42))\n",
    "#                 ]\n",
    "#             ),\n",
    "#     'pipe_params':{'classifier__loss':['hinge'],'classifier__max_iter':[7500]}, #'squared_error'\n",
    "#     'params':{\n",
    "#         # 'X_': [X_[0:1000]],\n",
    "#         # 'Z_':[Z_[0:200]],\n",
    "#         # 'y_train_v_': [y_train_v_[0:1000]],\n",
    "#         # 'y_test_v_':[y_test_v_[0:200]],\n",
    "#         # 'all_tokens_':[all_tokens_]\n",
    "#         **{ k:[v]  for (k,v) in berts_use_params['HF'].items()}\n",
    "#     }\n",
    "# }\n",
    "#embedding,input_tokens,Y_tokens,nb_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run_config([],config7,7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### config8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config8 = {\n",
    "#     'pipe':Pipeline( \n",
    "#                 steps=[\n",
    "#                     ('classifier' , SGDClassifier(n_jobs=-1,random_state=42))\n",
    "#                 ]\n",
    "#             ),\n",
    "#     'pipe_params':{'classifier__loss':['hinge'],'classifier__max_iter':[7500]},\n",
    "#     'params':{\n",
    "#         **{ k:[v]  for (k,v) in berts_use_params['TFhub'].items()}\n",
    "#     }\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results8 = do_supervised_classify(data,config8)\n",
    "# save_result(results8,'supvs_res8')\n",
    "# save_model(results8,['model','vectorizer','name'],'supvs_res8')\n",
    "# pd.DataFrame(df_results(results8))\n",
    "#run_config([],config8,8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### config9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config9 = {\n",
    "#     'pipe':Pipeline( \n",
    "#                 steps=[\n",
    "#                     ('classifier' , SGDClassifier(n_jobs=-1,random_state=42))\n",
    "#                 ]\n",
    "#             ),\n",
    "#     'pipe_params':{'classifier__loss':['hinge'],'classifier__max_iter':[7500]},\n",
    "#     'params':{\n",
    "#         **{ k:[v]  for (k,v) in berts_use_params['USE'].items()}\n",
    "#     }\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_config([],config9,9)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7b8c1420fd4668c3125a30c19ada9a198156baf5bd8e9521b9be91b166ac9fd7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-text in c:\\opt\\anaconda3\\lib\\site-packages (2.9.0)\n",
      "Requirement already satisfied: tensorflow-hub>=0.8.0 in c:\\opt\\anaconda3\\lib\\site-packages (from tensorflow-text) (0.12.0)\n",
      "Requirement already satisfied: tensorflow<2.10,>=2.9.0 in c:\\opt\\anaconda3\\lib\\site-packages (from tensorflow-text) (2.9.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\opt\\anaconda3\\lib\\site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (14.0.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\opt\\anaconda3\\lib\\site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (1.12.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\opt\\anaconda3\\lib\\site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (0.26.0)\n",
      "Requirement already satisfied: flatbuffers<2,>=1.12 in c:\\opt\\anaconda3\\lib\\site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (1.12)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\opt\\anaconda3\\lib\\site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (1.0.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\opt\\anaconda3\\lib\\site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (4.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\opt\\anaconda3\\lib\\site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (3.3.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\opt\\anaconda3\\lib\\site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (1.42.0)\n",
      "Requirement already satisfied: tensorboard<2.10,>=2.9 in c:\\opt\\anaconda3\\lib\\site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (2.9.0)\n",
      "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in c:\\opt\\anaconda3\\lib\\site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (2.9.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\opt\\anaconda3\\lib\\site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (1.1.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\opt\\anaconda3\\lib\\site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (1.16.0)\n",
      "Requirement already satisfied: setuptools in c:\\opt\\anaconda3\\lib\\site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (61.2.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in c:\\opt\\anaconda3\\lib\\site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (2.9.0)\n",
      "Requirement already satisfied: packaging in c:\\opt\\anaconda3\\lib\\site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (21.3)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\opt\\anaconda3\\lib\\site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (1.6.3)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\opt\\anaconda3\\lib\\site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (3.6.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\opt\\anaconda3\\lib\\site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\opt\\anaconda3\\lib\\site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (1.21.5)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\opt\\anaconda3\\lib\\site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (0.4.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\opt\\anaconda3\\lib\\site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (3.19.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\opt\\anaconda3\\lib\\site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (0.2.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\opt\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow<2.10,>=2.9.0->tensorflow-text) (0.37.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\opt\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (2.27.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\opt\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (0.4.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\opt\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (1.33.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\opt\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\opt\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (1.8.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\opt\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (3.3.4)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\opt\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (2.0.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\opt\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\opt\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (4.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\opt\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\opt\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\opt\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\opt\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\opt\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\opt\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\opt\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (2021.10.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\opt\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (3.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\opt\\anaconda3\\lib\\site-packages (from packaging->tensorflow<2.10,>=2.9.0->tensorflow-text) (3.0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path,PureWindowsPath,PurePosixPath\n",
    "import re\n",
    "import csv\n",
    "import io\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file  = \"QueryResults.csv\"\n",
    "output_file = \"stackOverFlow.csv\"\n",
    "Q_file      = \"stackOverFlow_Q.csv\"\n",
    "path = PureWindowsPath(r'C:\\Users\\benjamin.bouchard\\Documents\\PERSONNEL\\OCR\\courseNLP\\P5\\final\\data')\n",
    "data = pd.read_csv(f'{path}/{Q_file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Qs = data[\"Questions\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bert Wording Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"How Do You Communicate Service Layer Messages/Errors to Higher Layers Using MVP?.  I'm currently writing an ASP.Net app from the UI down. I'm implementing an MVP architecture because I'm sick of Winforms and wanted something that had a better separation of concerns.  So with MVP, the Presenter handles events raised by the View. Here's some code that I have in place to deal with the creation of users:  [CSS+Lasso]  I have my main form validation done using the built in .Net Validation Controls, but now I need to verify that the data sufficiently satisfies the criteria for the Service Layer.  Let's say the following Service Layer messages can show up:  E-mail account already exists (failure)  Refering user entered does not exist (failure)  Password length exceeds datastore allowed length (failure)  Member created successfully (success)  Let's also say that more rules will be in the service layer that the UI cannot anticipate.  Currently I'm having the service layer throw an exception if things didn't go as planned. Is that a sufficent strategy? Does this code smell to you guys? If I wrote a service layer like this would you be annoyed at having to write Presenters that use it in this way? Return codes seem too old school and a bool is just not informative enough.  Edit not by OP: merging in follow-up comments that were posted as answers by the OP  Cheekysoft, I like the concept of a ServiceLayerException. I already have a global exception module for the exceptions that I don't anticipate. Do you find making all these custom exceptions tedious? I was thinking that catching base Exception class was a bit smelly but wasn't exactly sure how progress from there.  tgmdbm, I like the clever use of the lambda expression there!  Thanks Cheekysoft for the follow-up. So I'm guessing that would be the strategy if you don't mind the user being displayed a separate page (I'm primarily a web developer) if the Exception is not handled.  However, if I want to return the error message in the same view where the user submitted the data that caused the error, I would then have to catch the Exception in the Presenter?  Here's what the CreateUserView looks like when the Presenter has handled the ServiceLayerException:  For this kind of error, it's nice to report it to the same view.  Anyways, I think we're going beyond the scope of my original question now. I'll play around with what you've posted and if I need further details I'll post a new question. \""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Qs[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_mask': <tf.Tensor: shape=(1, 128), dtype=int32, numpy=\n",
       " array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])>,\n",
       " 'input_type_ids': <tf.Tensor: shape=(1, 128), dtype=int32, numpy=\n",
       " array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])>,\n",
       " 'input_word_ids': <tf.Tensor: shape=(1, 128), dtype=int32, numpy=\n",
       " array([[  101,  1731,  2091,  1192,  3291,  6262, 19782, 20127,  2516,\n",
       "         22002,  1200, 24931,  1116,   120,   142, 13656,  1733,  1106,\n",
       "          7715, 22002,  1468,  7993, 12162,   136,   119,   146,   112,\n",
       "           182,  1971,  2269,  1126, 15278,  2101,   119, 20820, 12647,\n",
       "          1121,  1103,   158,  2240,  1205,   119,   146,   112,   182,\n",
       "         16381,  1126, 12162,  4220,  1272,   146,   112,   182,  4809,\n",
       "          1104, 16387, 13199,  1116,  1105,  1458,  1380,  1115,  1125,\n",
       "           170,  1618,  8865,  1104,  5365,   119,  1573,  1114, 12162,\n",
       "           117,  1103, 13653,  1200, 17180,  1958,  2120,  1118,  1103,\n",
       "         10344,   119,  3446,   112,   188,  1199,  3463,  1115,   146,\n",
       "          1138,  1107,  1282,  1106,  2239,  1114,  1103,  3707,  1104,\n",
       "          4713,   131,   164, 24821,  1708,   116,  5976,  7301,   166,\n",
       "           146,  1138,  1139,  1514,  1532,  9221,  1891,  1694,  1606,\n",
       "          1103,  1434,  1107,   119, 20820, 12226,  6859,  2116,  6342,\n",
       "          1116,   102]])>}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfhub_handle_preprocess = \"https://tfhub.dev/tensorflow/bert_en_cased_preprocess/3\"\n",
    "bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess)\n",
    "\n",
    "text_test = [Qs[7]]\n",
    "text_preprocessed = bert_preprocess_model(text_test)\n",
    "text_preprocessed\n",
    "#tfhub_handle_encoder = \"https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/4\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Universal Sentence Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is the difference between #include <filename> and #include \"filename\"?.  In the C and C++ programming languages, what is the difference between using angle brackets and using quotes in an  [Tera Term macro]  statement, as follows?  [Arduino]  [C] '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Qs[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Embedding as a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
    "embed([Qs[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Embedding using a Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 415ms/step\n",
      "(2, 512)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.01788572,  0.00237409,  0.00673477, ...,  0.06602099,\n",
       "        -0.02383039, -0.06340342],\n",
       "       [-0.02748683, -0.04152428,  0.00301326, ...,  0.0246256 ,\n",
       "         0.02267475, -0.05142068]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
    "inputs = tf.keras.Input(shape=tf.shape(''), dtype=tf.string)\n",
    "outputs = embed_layer(inputs)\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "embeddings = model.predict(tf.data.Dataset.from_tensor_slices(Qs.iloc[4:6]).batch(5))\n",
    "print(embeddings.shape)\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#8232713 49750645\n",
    "#test = data[data['Id'] == 50895806]\n",
    "#parser_list = html_parser.MyHTMLParser(filter= lambda x: False)\n",
    "#parser_str = html_parser.MyHTMLParser(filter= lambda x: False,container=html_parser.MixContainer)\n",
    "#res = test['Body'].apply(html_parser.do_parse,args=(parser_str,))\n",
    "#res.iloc[0]\n",
    "#from pygments.lexers import guess_lexer\n",
    "#str = \"XmlInclude\"\n",
    "#lexer = guess_lexer(str)\n",
    "#lexer.name\n",
    "test = data.iloc[1000:1100].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse html content in Body column\n",
    "def define_questions(data):\n",
    "    # parse body\n",
    "    data['Body-parsed'] = data['Body'].apply(html_parser.do_parse,args=(html_parser.MyHTMLParser(filter= lambda x: False,container=html_parser.MixContainer ),))\n",
    "    # concatenate title plus parse body\n",
    "    data['Questions'] = data[['Title','Body-parsed']].apply(lambda r: r['Title'] + '. ' + r['Body-parsed'],axis=1)\n",
    "\n",
    "#with io.open(f'{path}/{file_questions}','w', encoding=\"utf8\") as f:\n",
    "#    _ = list(map(lambda r: f.write(r+'\\n'),buffer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "define_questions(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = tf.data.TextLineDataset([f'{path}/{file_questions}'])\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices(test[\"Questions\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7b8c1420fd4668c3125a30c19ada9a198156baf5bd8e9521b9be91b166ac9fd7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

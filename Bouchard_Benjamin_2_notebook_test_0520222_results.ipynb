{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Modules import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# import math\n",
    "# import re\n",
    "# from collections import defaultdict\n",
    "# from html.parser import HTMLParser\n",
    "# from itertools import accumulate,chain,takewhile\n",
    "# import itertools\n",
    "# import warnings\n",
    "# import itertools\n",
    "# from pathlib import Path,PureWindowsPath,PurePosixPath\n",
    "\n",
    "# #wordcloud\n",
    "# import wordcloud\n",
    "\n",
    "# # \n",
    "# from scipy.sparse import csr_matrix\n",
    "\n",
    "# #pygments\n",
    "# from pygments.lexers import guess_lexer\n",
    "# from pygments.util  import ClassNotFound\n",
    "\n",
    "# # sklearn\n",
    "# from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "# from sklearn.preprocessing import MultiLabelBinarizer,StandardScaler\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.multiclass import OneVsRestClassifier\n",
    "# from sklearn.linear_model import SGDClassifier\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.metrics import jaccard_score,confusion_matrix\n",
    "\n",
    "\n",
    "# #gensim\n",
    "# from gensim.models.ldamodel import LdaModel\n",
    "# from gensim.corpora import Dictionary\n",
    "\n",
    "# #vis\n",
    "# import pyLDAvis\n",
    "# import pyLDAvis.gensim_models as gensimvis\n",
    "\n",
    "# #nltk\n",
    "# import nltk\n",
    "\n",
    "# #spacy\n",
    "# import spacy\n",
    "\n",
    "# #bitarray\n",
    "# # from  bitarray import bitarray\n",
    "# # from  bitarray.util import ba2int\n",
    "\n",
    "# #joblib\n",
    "# import joblib\n",
    "\n",
    "# #local\n",
    "# from Bouchard_Benjamin_1_notebook_exploration_0520222 import *\n",
    "# import vectorizer as vectz\n",
    "# import lda as ldam\n",
    "\n",
    "# # from importlib import reload\n",
    "# # reload(vectz)\n",
    "# warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from src import io_file\n",
    "from src import tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Affichage r√©sultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_param      = lambda d,n: d['params'][n] if d['params'].get(n) is not None else 'N.A'\n",
    "get_pipe_param = lambda d,n: d['pipe_params'][n] if d['pipe_params'].get(n) is not None else 'N.A'\n",
    "\n",
    "get_row_result = lambda d: [tools.loss_trans(get_pipe_param(d,'classifier__loss'))] + \\\n",
    "                            [tools.vect_trans(get_param(d,'vect'))] + \\\n",
    "                            [get_param(d,n) for n in ['nb_tags','body_tokens']] + \\\n",
    "                            [ str(round(100*get_param(d,n),4)) + '%' if get_param(d,n) != 'N.A' else get_param(d,n)  for n in ['body_min_df','body_max_df','title_min_df','title_max_df'] ] + \\\n",
    "                            [d['jaccard']] + \\\n",
    "                            [len(d['pipe_params']['steps']) == 2]   \n",
    "\n",
    "get_results = lambda res: [get_row_result(res[k]) for k in res.keys()]\n",
    "\n",
    "#\n",
    "def set_vect(d,v):\n",
    "     for k in d.keys():\n",
    "          d[k]['params']['vect'] = v\n",
    "\n",
    "df_results = lambda res: pd.DataFrame(data=get_results(res),columns=['Classifier','Vectoriser','Nb Tags','Body tokens','body_min_df','body_max_df','title_min_df','title_max_df','score','scaler'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "[res0,res1,res2,res3,res4,res5,res7,res8,res9] = list(map(lambda i: io_file.load_results(i),[0,1,2,3,4,5,7,8,9]))\n",
    "set_vect(res4,'w2v')\n",
    "set_vect(res5,'w2v')\n",
    "set_vect(res7,'BERT_HF')\n",
    "set_vect(res8,'BERT_TFhub')\n",
    "set_vect(res9,'USE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Vectoriser</th>\n",
       "      <th>Nb Tags</th>\n",
       "      <th>Body tokens</th>\n",
       "      <th>body_min_df</th>\n",
       "      <th>body_max_df</th>\n",
       "      <th>title_min_df</th>\n",
       "      <th>title_max_df</th>\n",
       "      <th>score</th>\n",
       "      <th>scaler</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>50</td>\n",
       "      <td>body-tokens</td>\n",
       "      <td>0.5999%</td>\n",
       "      <td>5.4576%</td>\n",
       "      <td>0.2122%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>0.029724</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>50</td>\n",
       "      <td>body-tokens</td>\n",
       "      <td>0.5999%</td>\n",
       "      <td>5.4576%</td>\n",
       "      <td>0.2122%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>0.048099</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>100</td>\n",
       "      <td>body-tokens</td>\n",
       "      <td>0.5999%</td>\n",
       "      <td>5.4576%</td>\n",
       "      <td>0.2122%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>0.018150</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>100</td>\n",
       "      <td>body-tokens</td>\n",
       "      <td>0.5999%</td>\n",
       "      <td>5.4576%</td>\n",
       "      <td>0.2122%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>0.036366</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVM</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>50</td>\n",
       "      <td>body-tokens</td>\n",
       "      <td>0.5999%</td>\n",
       "      <td>5.4576%</td>\n",
       "      <td>0.2122%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>0.127420</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVM</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>50</td>\n",
       "      <td>body-tokens</td>\n",
       "      <td>0.5999%</td>\n",
       "      <td>5.4576%</td>\n",
       "      <td>0.2122%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>0.122054</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SVM</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>100</td>\n",
       "      <td>body-tokens</td>\n",
       "      <td>0.5999%</td>\n",
       "      <td>5.4576%</td>\n",
       "      <td>0.2122%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>0.064221</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SVM</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>100</td>\n",
       "      <td>body-tokens</td>\n",
       "      <td>0.5999%</td>\n",
       "      <td>5.4576%</td>\n",
       "      <td>0.2122%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>0.059194</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>50</td>\n",
       "      <td>body-tokens</td>\n",
       "      <td>1.7631%</td>\n",
       "      <td>5.4576%</td>\n",
       "      <td>0.7535%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>0.029113</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>50</td>\n",
       "      <td>body-tokens</td>\n",
       "      <td>1.7631%</td>\n",
       "      <td>5.4576%</td>\n",
       "      <td>0.7535%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>0.046729</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>100</td>\n",
       "      <td>body-tokens</td>\n",
       "      <td>1.7631%</td>\n",
       "      <td>5.4576%</td>\n",
       "      <td>0.7535%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>0.017248</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>100</td>\n",
       "      <td>body-tokens</td>\n",
       "      <td>1.7631%</td>\n",
       "      <td>5.4576%</td>\n",
       "      <td>0.7535%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>0.031620</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVM</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>50</td>\n",
       "      <td>body-tokens</td>\n",
       "      <td>1.7631%</td>\n",
       "      <td>5.4576%</td>\n",
       "      <td>0.7535%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>0.097383</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVM</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>50</td>\n",
       "      <td>body-tokens</td>\n",
       "      <td>1.7631%</td>\n",
       "      <td>5.4576%</td>\n",
       "      <td>0.7535%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>0.077323</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SVM</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>100</td>\n",
       "      <td>body-tokens</td>\n",
       "      <td>1.7631%</td>\n",
       "      <td>5.4576%</td>\n",
       "      <td>0.7535%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>0.046688</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SVM</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>100</td>\n",
       "      <td>body-tokens</td>\n",
       "      <td>1.7631%</td>\n",
       "      <td>5.4576%</td>\n",
       "      <td>0.7535%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>0.039876</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>50</td>\n",
       "      <td>body-tokens-wov</td>\n",
       "      <td>0.3841%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>0.2122%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>0.028892</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>50</td>\n",
       "      <td>body-tokens-wov</td>\n",
       "      <td>0.3841%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>0.2122%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>0.044701</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>100</td>\n",
       "      <td>body-tokens-wov</td>\n",
       "      <td>0.3841%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>0.2122%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>0.018158</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>100</td>\n",
       "      <td>body-tokens-wov</td>\n",
       "      <td>0.3841%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>0.2122%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>0.057034</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVM</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>50</td>\n",
       "      <td>body-tokens-wov</td>\n",
       "      <td>0.3841%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>0.2122%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>0.129706</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVM</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>50</td>\n",
       "      <td>body-tokens-wov</td>\n",
       "      <td>0.3841%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>0.2122%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>0.122976</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SVM</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>100</td>\n",
       "      <td>body-tokens-wov</td>\n",
       "      <td>0.3841%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>0.2122%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>0.072046</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SVM</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>100</td>\n",
       "      <td>body-tokens-wov</td>\n",
       "      <td>0.3841%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>0.2122%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>0.062126</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>50</td>\n",
       "      <td>body-tokens-wov</td>\n",
       "      <td>0.3841%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>0.2122%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>0.027321</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>100</td>\n",
       "      <td>body-tokens-wov</td>\n",
       "      <td>0.3841%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>0.2122%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>0.022612</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>50</td>\n",
       "      <td>body-tokens-wov</td>\n",
       "      <td>0.3841%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>0.2122%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>0.301102</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>100</td>\n",
       "      <td>body-tokens-wov</td>\n",
       "      <td>0.3841%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>0.2122%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>0.283077</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>w2v</td>\n",
       "      <td>50</td>\n",
       "      <td>body-tokens-wov</td>\n",
       "      <td>0.3841%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>0.2122%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>0.273206</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>w2v</td>\n",
       "      <td>100</td>\n",
       "      <td>body-tokens-wov</td>\n",
       "      <td>0.3841%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>0.2122%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>0.226119</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM</td>\n",
       "      <td>w2v</td>\n",
       "      <td>50</td>\n",
       "      <td>body-tokens-wov</td>\n",
       "      <td>0.3841%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>0.2122%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>0.301102</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM</td>\n",
       "      <td>w2v</td>\n",
       "      <td>100</td>\n",
       "      <td>body-tokens-wov</td>\n",
       "      <td>0.3841%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>0.2122%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>0.283077</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>w2v</td>\n",
       "      <td>50</td>\n",
       "      <td>body-tokens</td>\n",
       "      <td>1.7631%</td>\n",
       "      <td>5.4576%</td>\n",
       "      <td>0.7535%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>0.467294</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>w2v</td>\n",
       "      <td>100</td>\n",
       "      <td>body-tokens</td>\n",
       "      <td>1.7631%</td>\n",
       "      <td>5.4576%</td>\n",
       "      <td>0.7535%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>0.316204</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM</td>\n",
       "      <td>w2v</td>\n",
       "      <td>50</td>\n",
       "      <td>body-tokens</td>\n",
       "      <td>1.7631%</td>\n",
       "      <td>5.4576%</td>\n",
       "      <td>0.7535%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>0.377323</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM</td>\n",
       "      <td>w2v</td>\n",
       "      <td>100</td>\n",
       "      <td>body-tokens</td>\n",
       "      <td>1.7631%</td>\n",
       "      <td>5.4576%</td>\n",
       "      <td>0.7535%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>0.398761</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>BERT_HF</td>\n",
       "      <td>N.A</td>\n",
       "      <td>N.A</td>\n",
       "      <td>N.A</td>\n",
       "      <td>N.A</td>\n",
       "      <td>N.A</td>\n",
       "      <td>N.A</td>\n",
       "      <td>0.564910</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM</td>\n",
       "      <td>BERT_HF</td>\n",
       "      <td>N.A</td>\n",
       "      <td>N.A</td>\n",
       "      <td>N.A</td>\n",
       "      <td>N.A</td>\n",
       "      <td>N.A</td>\n",
       "      <td>N.A</td>\n",
       "      <td>0.564880</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>BERT_TFhub</td>\n",
       "      <td>N.A</td>\n",
       "      <td>N.A</td>\n",
       "      <td>N.A</td>\n",
       "      <td>N.A</td>\n",
       "      <td>N.A</td>\n",
       "      <td>N.A</td>\n",
       "      <td>0.559082</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM</td>\n",
       "      <td>BERT_TFhub</td>\n",
       "      <td>N.A</td>\n",
       "      <td>N.A</td>\n",
       "      <td>N.A</td>\n",
       "      <td>N.A</td>\n",
       "      <td>N.A</td>\n",
       "      <td>N.A</td>\n",
       "      <td>0.552005</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>USE</td>\n",
       "      <td>N.A</td>\n",
       "      <td>N.A</td>\n",
       "      <td>N.A</td>\n",
       "      <td>N.A</td>\n",
       "      <td>N.A</td>\n",
       "      <td>N.A</td>\n",
       "      <td>0.535896</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM</td>\n",
       "      <td>USE</td>\n",
       "      <td>N.A</td>\n",
       "      <td>N.A</td>\n",
       "      <td>N.A</td>\n",
       "      <td>N.A</td>\n",
       "      <td>N.A</td>\n",
       "      <td>N.A</td>\n",
       "      <td>0.590596</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Classifier       Vectoriser Nb Tags      Body tokens body_min_df  \\\n",
       "0   Logistic  CountVectorizer      50      body-tokens     0.5999%   \n",
       "1   Logistic  TfidfVectorizer      50      body-tokens     0.5999%   \n",
       "2   Logistic  CountVectorizer     100      body-tokens     0.5999%   \n",
       "3   Logistic  TfidfVectorizer     100      body-tokens     0.5999%   \n",
       "4        SVM  CountVectorizer      50      body-tokens     0.5999%   \n",
       "5        SVM  TfidfVectorizer      50      body-tokens     0.5999%   \n",
       "6        SVM  CountVectorizer     100      body-tokens     0.5999%   \n",
       "7        SVM  TfidfVectorizer     100      body-tokens     0.5999%   \n",
       "0   Logistic  CountVectorizer      50      body-tokens     1.7631%   \n",
       "1   Logistic  TfidfVectorizer      50      body-tokens     1.7631%   \n",
       "2   Logistic  CountVectorizer     100      body-tokens     1.7631%   \n",
       "3   Logistic  TfidfVectorizer     100      body-tokens     1.7631%   \n",
       "4        SVM  CountVectorizer      50      body-tokens     1.7631%   \n",
       "5        SVM  TfidfVectorizer      50      body-tokens     1.7631%   \n",
       "6        SVM  CountVectorizer     100      body-tokens     1.7631%   \n",
       "7        SVM  TfidfVectorizer     100      body-tokens     1.7631%   \n",
       "0   Logistic  CountVectorizer      50  body-tokens-wov     0.3841%   \n",
       "1   Logistic  TfidfVectorizer      50  body-tokens-wov     0.3841%   \n",
       "2   Logistic  CountVectorizer     100  body-tokens-wov     0.3841%   \n",
       "3   Logistic  TfidfVectorizer     100  body-tokens-wov     0.3841%   \n",
       "4        SVM  CountVectorizer      50  body-tokens-wov     0.3841%   \n",
       "5        SVM  TfidfVectorizer      50  body-tokens-wov     0.3841%   \n",
       "6        SVM  CountVectorizer     100  body-tokens-wov     0.3841%   \n",
       "7        SVM  TfidfVectorizer     100  body-tokens-wov     0.3841%   \n",
       "0   Logistic  TfidfVectorizer      50  body-tokens-wov     0.3841%   \n",
       "1   Logistic  TfidfVectorizer     100  body-tokens-wov     0.3841%   \n",
       "2        SVM  TfidfVectorizer      50  body-tokens-wov     0.3841%   \n",
       "3        SVM  TfidfVectorizer     100  body-tokens-wov     0.3841%   \n",
       "0   Logistic              w2v      50  body-tokens-wov     0.3841%   \n",
       "1   Logistic              w2v     100  body-tokens-wov     0.3841%   \n",
       "2        SVM              w2v      50  body-tokens-wov     0.3841%   \n",
       "3        SVM              w2v     100  body-tokens-wov     0.3841%   \n",
       "0   Logistic              w2v      50      body-tokens     1.7631%   \n",
       "1   Logistic              w2v     100      body-tokens     1.7631%   \n",
       "2        SVM              w2v      50      body-tokens     1.7631%   \n",
       "3        SVM              w2v     100      body-tokens     1.7631%   \n",
       "0   Logistic          BERT_HF     N.A              N.A         N.A   \n",
       "1        SVM          BERT_HF     N.A              N.A         N.A   \n",
       "0   Logistic       BERT_TFhub     N.A              N.A         N.A   \n",
       "1        SVM       BERT_TFhub     N.A              N.A         N.A   \n",
       "0   Logistic              USE     N.A              N.A         N.A   \n",
       "1        SVM              USE     N.A              N.A         N.A   \n",
       "\n",
       "  body_max_df title_min_df title_max_df     score  scaler  \n",
       "0     5.4576%      0.2122%       100.0%  0.029724    True  \n",
       "1     5.4576%      0.2122%       100.0%  0.048099    True  \n",
       "2     5.4576%      0.2122%       100.0%  0.018150    True  \n",
       "3     5.4576%      0.2122%       100.0%  0.036366    True  \n",
       "4     5.4576%      0.2122%       100.0%  0.127420    True  \n",
       "5     5.4576%      0.2122%       100.0%  0.122054    True  \n",
       "6     5.4576%      0.2122%       100.0%  0.064221    True  \n",
       "7     5.4576%      0.2122%       100.0%  0.059194    True  \n",
       "0     5.4576%      0.7535%       100.0%  0.029113    True  \n",
       "1     5.4576%      0.7535%       100.0%  0.046729    True  \n",
       "2     5.4576%      0.7535%       100.0%  0.017248    True  \n",
       "3     5.4576%      0.7535%       100.0%  0.031620    True  \n",
       "4     5.4576%      0.7535%       100.0%  0.097383    True  \n",
       "5     5.4576%      0.7535%       100.0%  0.077323    True  \n",
       "6     5.4576%      0.7535%       100.0%  0.046688    True  \n",
       "7     5.4576%      0.7535%       100.0%  0.039876    True  \n",
       "0      100.0%      0.2122%       100.0%  0.028892    True  \n",
       "1      100.0%      0.2122%       100.0%  0.044701    True  \n",
       "2      100.0%      0.2122%       100.0%  0.018158    True  \n",
       "3      100.0%      0.2122%       100.0%  0.057034    True  \n",
       "4      100.0%      0.2122%       100.0%  0.129706    True  \n",
       "5      100.0%      0.2122%       100.0%  0.122976    True  \n",
       "6      100.0%      0.2122%       100.0%  0.072046    True  \n",
       "7      100.0%      0.2122%       100.0%  0.062126    True  \n",
       "0      100.0%      0.2122%       100.0%  0.027321   False  \n",
       "1      100.0%      0.2122%       100.0%  0.022612   False  \n",
       "2      100.0%      0.2122%       100.0%  0.301102   False  \n",
       "3      100.0%      0.2122%       100.0%  0.283077   False  \n",
       "0      100.0%      0.2122%       100.0%  0.273206   False  \n",
       "1      100.0%      0.2122%       100.0%  0.226119   False  \n",
       "2      100.0%      0.2122%       100.0%  0.301102   False  \n",
       "3      100.0%      0.2122%       100.0%  0.283077   False  \n",
       "0     5.4576%      0.7535%       100.0%  0.467294   False  \n",
       "1     5.4576%      0.7535%       100.0%  0.316204   False  \n",
       "2     5.4576%      0.7535%       100.0%  0.377323   False  \n",
       "3     5.4576%      0.7535%       100.0%  0.398761   False  \n",
       "0         N.A          N.A          N.A  0.564910   False  \n",
       "1         N.A          N.A          N.A  0.564880   False  \n",
       "0         N.A          N.A          N.A  0.559082   False  \n",
       "1         N.A          N.A          N.A  0.552005   False  \n",
       "0         N.A          N.A          N.A  0.535896   False  \n",
       "1         N.A          N.A          N.A  0.590596   False  "
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat( [ df_results(res0),df_results(res1),df_results(res2),df_results(res3),df_results(res4),df_results(res5),df_results(res7),df_results(res8),df_results(res9)])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7b8c1420fd4668c3125a30c19ada9a198156baf5bd8e9521b9be91b166ac9fd7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
